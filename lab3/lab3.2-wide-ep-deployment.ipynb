{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 3.2: Wide EP Production Deployment\n",
    "\n",
    "## üéØ Overview\n",
    "\n",
    "Welcome to Lab 3.2! Now that you understand Expert Parallelism concepts from Lab 3.1, you'll **deploy a real MoE model** (DeepSeek-R1) using Wide EP in a production Kubernetes environment.\n",
    "\n",
    "**What you'll do in this lab:**\n",
    "1. ‚úÖ Verify your environment is ready\n",
    "2. üîß Build a custom Docker image with DeepEP support\n",
    "3. üöÄ Deploy DeepSeek-R1 with Wide Expert Parallelism\n",
    "4. üìä Monitor expert load balancing (EPLB) in action\n",
    "5. üéØ Benchmark and optimize performance\n",
    "\n",
    "**Time Required**: 90-120 minutes (includes Docker image build)\n",
    "\n",
    "**Hardware Requirements**: \n",
    "- 16 GPUs minimum (2 nodes √ó 8 GPUs each)\n",
    "- High-bandwidth interconnect (NVLink or InfiniBand recommended)\n",
    "\n",
    "---\n",
    "\n",
    "## ‚ö†Ô∏è Before You Start\n",
    "\n",
    "**Prerequisites (must be completed first):**\n",
    "- ‚úÖ Lab 3.1: Expert Parallelism Foundations\n",
    "- ‚úÖ Kubernetes cluster with GPU nodes\n",
    "- ‚úÖ **Dynamo Operator already installed** (from Lab 1 or Lab 2)\n",
    "- ‚úÖ kubectl configured and working\n",
    "- ‚úÖ HuggingFace account with access token\n",
    "\n",
    "üí° **Note**: This lab assumes you've completed Lab 1 or Lab 2, where you installed the Dynamo Operator. We'll skip the operator installation and focus on deploying the MoE model.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìã Table of Contents\n",
    "\n",
    "**Part 1: Setup & Prerequisites**\n",
    "- [Quick Recap: Lab 3.1 Concepts](#Quick-Recap:-Lab-3.1-Concepts)\n",
    "- [Prerequisites Check](#Prerequisites-Check)\n",
    "\n",
    "**Part 2: Deployment**\n",
    "- [Understanding Your Deployment Options](#Understanding-Your-Deployment-Options)\n",
    "- [Step-by-Step Deployment Guide](#Step-by-Step-Deployment-Guide)\n",
    "\n",
    "**Part 3: Configuration Deep Dive**\n",
    "- [SGLang Configuration Details](#Section-3:-Deploying-MoE-Models-with-SGLang-and-Expert-Parallelism)\n",
    "- [Monitoring Expert Parallelism and EPLB](#Monitoring-Expert-Parallelism-and-EPLB)\n",
    "\n",
    "**Part 4: Performance**\n",
    "- [Benchmarking Your Deployment](#Section-4:-Performance-Benchmarking-for-EP-Deployments)\n",
    "\n",
    "**Wrap-Up**\n",
    "- [Summary](#Summary)\n",
    "\n",
    "---\n",
    "\n",
    "## üîÑ Quick Recap: Lab 3.1 Concepts\n",
    "\n",
    "In Lab 3.1, you learned the foundations of Expert Parallelism. Here's a quick refresher:\n",
    "\n",
    "**Key Concepts**:\n",
    "- **MoE Models**: Only activate a subset of experts per token (e.g., 8 out of 256 experts)\n",
    "- **Expert Parallelism (EP)**: Distribute experts across GPUs to scale capacity\n",
    "- **Wide EP**: Spread experts across many nodes for maximum throughput\n",
    "- **EPLB**: Dynamic load balancing to prevent GPU hotspots\n",
    "\n",
    "**What you're deploying today:**\n",
    "```\n",
    "DeepSeek-R1 Model:\n",
    "  - 671B total parameters\n",
    "  - 256 experts (distributed via EP)\n",
    "  - Only 8 experts active per token (~37B active params)\n",
    "  - Disaggregated: Separate prefill & decode workers\n",
    "```\n",
    "\n",
    "**Deployment Architecture** (what we're building):\n",
    "```\n",
    "                ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
    "                ‚îÇ  Frontend   ‚îÇ\n",
    "                ‚îÇ  (CPU)      ‚îÇ\n",
    "                ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
    "                       ‚îÇ\n",
    "           ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
    "           ‚îÇ                       ‚îÇ\n",
    "    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê       ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
    "    ‚îÇ Prefill Worker‚îÇ       ‚îÇ Decode Worker ‚îÇ\n",
    "    ‚îÇ   Node 1      ‚îÇ       ‚îÇ   Node 2      ‚îÇ\n",
    "    ‚îÇ   8 GPUs      ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ   8 GPUs      ‚îÇ\n",
    "    ‚îÇ               ‚îÇ NIXL  ‚îÇ               ‚îÇ\n",
    "    ‚îÇ  TP=8, EP=8   ‚îÇ  KV   ‚îÇ TP=8, DP=8    ‚îÇ\n",
    "    ‚îÇ               ‚îÇ       ‚îÇ EP=8          ‚îÇ\n",
    "    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò       ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
    "```\n",
    "\n",
    "Now let's verify your environment and deploy!\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‚úÖ Prerequisites Check\n",
    "\n",
    "Before we start deploying, let's verify your environment is ready. Run the following checks:\n",
    "\n",
    "---\n",
    "\n",
    "### Check 1: Verify Kubernetes Access\n",
    "\n",
    "Make sure you can access your Kubernetes cluster and see your GPU nodes.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check 2: Verify GPU Availability\n",
    "\n",
    "Check that you have at least 16 GPUs available across your nodes:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "# Check Kubernetes access and nodes\n",
    "echo \"=== Kubernetes Cluster Info ===\"\n",
    "kubectl cluster-info\n",
    "\n",
    "echo -e \"\\n=== GPU Nodes ===\"\n",
    "kubectl get nodes -o custom-columns=NAME:.metadata.name,GPUs:.status.allocatable.'nvidia\\.com/gpu'\n",
    "\n",
    "echo -e \"\\n‚úÖ If you see your nodes with GPUs listed above, you're good to go!\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check 3: Verify Dynamo Operator is Installed\n",
    "\n",
    "Since you completed Lab 1 or Lab 2, the Dynamo Operator should already be installed. Let's verify:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "export NAMESPACE=\"dynamo-workshop\"\n",
    "\n",
    "echo \"=== Checking Dynamo CRDs ===\"\n",
    "kubectl get crd | grep dynamo || echo \"‚ö†Ô∏è  No Dynamo CRDs found!\"\n",
    "\n",
    "echo -e \"\\n=== Checking Dynamo Operator Pod ===\"\n",
    "kubectl get pods -n ${NAMESPACE} -l app.kubernetes.io/name=dynamo-operator || echo \"‚ö†Ô∏è  Dynamo operator not found!\"\n",
    "\n",
    "echo -e \"\\n=== Checking Platform Components ===\"\n",
    "kubectl get pods -n ${NAMESPACE}\n",
    "\n",
    "echo -e \"\\n‚úÖ If you see dynamo-operator, etcd, and nats pods Running above, you're ready!\"\n",
    "echo \"‚ö†Ô∏è  If not, please complete Lab 1 or Lab 2 first to install the Dynamo Operator.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 3: Create Namespace and Install Dynamo Platform\n",
    "\n",
    "Create the workshop namespace and install the Dynamo platform components (operator, etcd, NATS).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "export NAMESPACE=\"dynamo-workshop\"\n",
    "\n",
    "# Create namespace\n",
    "# kubectl create namespace ${NAMESPACE}\n",
    "\n",
    "# Fetch and install Dynamo platform\n",
    "# helm fetch https://helm.ngc.nvidia.com/nvidia/ai-dynamo/charts/dynamo-platform-0.6.0.tgz\n",
    "# helm install dynamo-platform dynamo-platform-0.6.0.tgz --namespace ${NAMESPACE} --set dynamo-operator.namespaceRestriction.enabled=true\n",
    "\n",
    "# Wait for platform pods to be ready\n",
    "echo \"Waiting for platform pods to be ready...\"\n",
    "kubectl wait --for=condition=ready pod -l app.kubernetes.io/name=dynamo-platform -n ${NAMESPACE} --timeout=300s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 4: Verify Platform Installation\n",
    "\n",
    "Check that all Dynamo platform components are running correctly.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "export NAMESPACE=\"dynamo-workshop\"\n",
    "\n",
    "# Check all pods in the namespace\n",
    "kubectl get pods -n ${NAMESPACE}\n",
    "\n",
    "# Expected output: dynamo-operator, etcd, and nats pods should be Running"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 5: Create HuggingFace Token Secret\n",
    "\n",
    "Create a Kubernetes secret with your HuggingFace token for model downloads. Replace `your_hf_token_here` with your actual token from https://huggingface.co/settings/tokens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "export NAMESPACE=\"dynamo-workshop\"\n",
    "\n",
    "# Create HuggingFace token secret\n",
    "# Replace 'your_hf_token_here' with your actual HF token\n",
    "kubectl create secret generic hf-token-secret \\\n",
    "  --from-literal=HF_TOKEN='your_hf_token_here' \\\n",
    "  -n ${NAMESPACE}\n",
    "\n",
    "# Verify secret was created\n",
    "kubectl get secret hf-token-secret -n ${NAMESPACE}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 5.5: Build Custom Docker Image\n",
    "\n",
    "The deployment requires a custom Docker image that includes DeepEP support for Wide EP functionality.\n",
    "\n",
    "**Build the image**:\n",
    "```bash\n",
    "cd /mnt/raid/dynamo-workshop/dynamo\n",
    "git checkout v0.6.0\n",
    "docker build -f container/Dockerfile.sglang-wideep -t dynamo-wideep:0.6.0 .\n",
    "```\n",
    "\n",
    "This uses the official Dockerfile from the Dynamo repository and typically takes 30-60 minutes.\n",
    "\n",
    "**For multi-node deployments**, push to your container registry:\n",
    "```bash\n",
    "docker tag dynamo-wideep:0.6.0 <your-registry>/dynamo-wideep:0.6.0\n",
    "docker push <your-registry>/dynamo-wideep:0.6.0\n",
    "```\n",
    "\n",
    "After building and pushing, update the manifests with your registry in the next cell.\n",
    "\n",
    "See the [official recipe](https://github.com/ai-dynamo/dynamo/tree/main/recipes/deepseek-r1/sglang-wideep) for more details.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "# Update manifests with your container registry\n",
    "# Replace <your-registry> with your actual registry (e.g., docker.io/username, gcr.io/project)\n",
    "\n",
    "cd /mnt/raid/dynamo-workshop/lab3\n",
    "\n",
    "# Update both manifests\n",
    "sed -i 's|<your-registry>/dynamo-wideep:0.6.0|your-actual-registry/dynamo-wideep:0.6.0|g' k8s/deepseek-r1-8gpu-singlenode.yaml\n",
    "sed -i 's|<your-registry>/dynamo-wideep:0.6.0|your-actual-registry/dynamo-wideep:0.6.0|g' k8s/deepseek-r1-16gpu-multinode.yaml\n",
    "\n",
    "echo \"‚úÖ Manifests updated with registry: your-actual-registry\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "echo \"=== Available Storage Classes ===\"\n",
    "kubectl get storageclass\n",
    "\n",
    "echo \"\"\n",
    "echo \"=== Storage Class Details (check for ReadWriteMany support) ===\"\n",
    "kubectl get storageclass -o custom-columns=NAME:.metadata.name,PROVISIONER:.provisioner,RECLAIM:.reclaimPolicy,VOLUMEBINDING:.volumeBindingMode\n",
    "\n",
    "echo \"\"\n",
    "echo \"üí° Look for storage classes that support ReadWriteMany (RWX) access mode\"\n",
    "echo \"   Common RWX provisioners: nfs, efs.csi.aws.com, file.csi.azure.com, filestore.csi.storage.gke.io\"\n",
    "echo \"\"\n",
    "echo \"üìù If you need to specify a storage class, edit k8s/model-cache-pvc.yaml\"\n",
    "echo \"   Uncomment and set: storageClassName: <your-rwx-storage-class>\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 5.6: Create Model Cache PVC (Optional but Recommended)\n",
    "\n",
    "To avoid downloading the model multiple times and speed up deployments, create a Persistent Volume Claim (PVC) to cache the model.\n",
    "\n",
    "**Benefits**:\n",
    "- ‚úÖ Download model once, reuse across deployments\n",
    "- ‚úÖ Faster pod startup times (no HuggingFace download)\n",
    "- ‚úÖ Reduced network bandwidth usage\n",
    "- ‚úÖ Consistent model versions across workers\n",
    "\n",
    "**Storage Requirements**: ~500GB for DeepSeek-R1 (671B parameters)\n",
    "\n",
    "**Important**: First check your cluster's available storage classes and update `k8s/model-cache-pvc.yaml` if needed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "export NAMESPACE=\"dynamo-workshop\"\n",
    "\n",
    "echo \"=== Creating Model Cache PVC ===\"\n",
    "kubectl apply -f k8s/model-cache-pvc.yaml\n",
    "\n",
    "echo \"\"\n",
    "echo \"=== Waiting for PVC to be bound ===\"\n",
    "kubectl wait --for=jsonpath='{.status.phase}'=Bound pvc/model-cache-pvc -n ${NAMESPACE} --timeout=300s\n",
    "\n",
    "echo \"\"\n",
    "echo \"‚úÖ PVC created and bound!\"\n",
    "kubectl get pvc model-cache-pvc -n ${NAMESPACE}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 5.7: Download Model to Cache (One-Time Setup)\n",
    "\n",
    "Run a Kubernetes Job to download the DeepSeek-R1 model to the PVC. This is a one-time operation that may take 15-30 minutes depending on your network speed.\n",
    "\n",
    "**What this does**:\n",
    "1. Creates a temporary pod with the model cache PVC mounted\n",
    "2. Downloads the full DeepSeek-R1 model from HuggingFace (~100GB)\n",
    "3. Stores it in `/model-cache/deepseek-r1` on the PVC\n",
    "4. Exits when complete\n",
    "\n",
    "**Note**: You can monitor progress with `kubectl logs -f job/deepseek-r1-model-download -n dynamo-workshop`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "export NAMESPACE=\"dynamo-workshop\"\n",
    "\n",
    "echo \"=== Starting Model Download Job ===\"\n",
    "kubectl apply -f k8s/model-download-job.yaml\n",
    "\n",
    "echo \"\"\n",
    "echo \"üì• Model download started. This may take 15-30 minutes...\"\n",
    "echo \"\"\n",
    "echo \"Monitor progress with:\"\n",
    "echo \"  kubectl logs -f job/deepseek-r1-model-download -n ${NAMESPACE}\"\n",
    "echo \"\"\n",
    "echo \"Check job status:\"\n",
    "kubectl get job deepseek-r1-model-download -n ${NAMESPACE}\n",
    "\n",
    "echo \"\"\n",
    "echo \"üí° The job will download ~100GB. You can proceed to the next steps once complete.\"\n",
    "echo \"   To wait for completion, run:\"\n",
    "echo \"   kubectl wait --for=condition=complete job/deepseek-r1-model-download -n ${NAMESPACE} --timeout=3600s\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 5.8: Verify Model Download (Optional)\n",
    "\n",
    "Check that the model was successfully downloaded to the PVC.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "export NAMESPACE=\"dynamo-workshop\"\n",
    "\n",
    "echo \"=== Checking Model Download Job Status ===\"\n",
    "kubectl get job deepseek-r1-model-download -n ${NAMESPACE}\n",
    "\n",
    "echo \"\"\n",
    "echo \"=== Job Logs (last 20 lines) ===\"\n",
    "kubectl logs job/deepseek-r1-model-download -n ${NAMESPACE} --tail=20 || echo \"Job not started yet or no logs available\"\n",
    "\n",
    "echo \"\"\n",
    "echo \"üí° Once the job shows 'Completions: 1/1', the model is ready!\"\n",
    "echo \"   You can then proceed to deploy DeepSeek-R1 using the cached model.\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 5.9: Clean Up Download Job (After Completion)\n",
    "\n",
    "Once the model download is complete (job shows `Completions: 1/1`), you can safely delete the download job. The downloaded model remains on the PVC.\n",
    "\n",
    "**Why clean up?**\n",
    "- Removes completed pods from the cluster\n",
    "- Frees up cluster resources\n",
    "- Keeps your namespace clean\n",
    "\n",
    "**Note**: This does NOT delete the downloaded model - only the job pod.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "export NAMESPACE=\"dynamo-workshop\"\n",
    "\n",
    "echo \"=== Checking if download is complete ===\"\n",
    "JOB_STATUS=$(kubectl get job deepseek-r1-model-download -n ${NAMESPACE} -o jsonpath='{.status.succeeded}' 2>/dev/null)\n",
    "\n",
    "if [ \"$JOB_STATUS\" = \"1\" ]; then\n",
    "    echo \"‚úÖ Download job completed successfully!\"\n",
    "    echo \"\"\n",
    "    echo \"=== Deleting download job ===\"\n",
    "    kubectl delete job deepseek-r1-model-download -n ${NAMESPACE}\n",
    "    echo \"\"\n",
    "    echo \"‚úÖ Job deleted. Model is safely stored on the PVC.\"\n",
    "else\n",
    "    echo \"‚ö†Ô∏è  Download job is not complete yet.\"\n",
    "    echo \"\"\n",
    "    echo \"Current status:\"\n",
    "    kubectl get job deepseek-r1-model-download -n ${NAMESPACE}\n",
    "    echo \"\"\n",
    "    echo \"üí° Wait for the job to complete before running this step.\"\n",
    "    echo \"   Monitor with: kubectl logs -f job/deepseek-r1-model-download -n ${NAMESPACE}\"\n",
    "fi\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 6: Deploy DeepSeek-R1 with Wide EP\n",
    "\n",
    "Deploy the DeepSeek-R1 model using the pre-configured Wide EP manifest. This will create a disaggregated deployment with prefill and decode workers.\n",
    "\n",
    "**Model Loading**:\n",
    "- ‚úÖ **With Model Cache** (Steps 5.6-5.8 completed): Workers will load from `/model-cache/deepseek-r1` (fast startup, ~2-5 minutes)\n",
    "- ‚ö†Ô∏è **Without Model Cache** (Steps 5.6-5.8 skipped): Workers will download from HuggingFace (slower startup, ~10-15 minutes per worker)\n",
    "\n",
    "The manifest `deepseek-r1-8gpu-singlenode.yaml` is already configured to use the model cache if available.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "export NAMESPACE=\"dynamo-workshop\"\n",
    "\n",
    "echo \"üöÄ Deploying DeepSeek-R1 with Wide Expert Parallelism...\"\n",
    "echo \"\"\n",
    "\n",
    "# Deploy using Single-Node Workers configuration (recommended)\n",
    "kubectl apply -f k8s/deepseek-r1-8gpu-singlenode.yaml -n ${NAMESPACE}\n",
    "\n",
    "# For multi-node deployment (if you have 4 nodes √ó 4 GPUs), use:\n",
    "# kubectl apply -f k8s/deepseek-r1-16gpu-multinode.yaml -n ${NAMESPACE}\n",
    "\n",
    "echo \"\"\n",
    "echo \"‚úÖ Deployment created!\"\n",
    "echo \"\"\n",
    "echo \"üìä Checking deployment status...\"\n",
    "kubectl get dynamographdeployment -n ${NAMESPACE}\n",
    "\n",
    "echo \"\"\n",
    "echo \"üí° The pods will now start. This may take 5-10 minutes as:\"\n",
    "echo \"   1. Model weights are downloaded from HuggingFace (~100GB)\"\n",
    "echo \"   2. Workers initialize and load the model into GPU memory\"\n",
    "echo \"   3. Expert Parallelism topology is established\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 7: Monitor Deployment Progress\n",
    "\n",
    "Watch the pods as they start up. This may take several minutes as the model is downloaded and loaded. Press Ctrl+C to stop watching.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "export NAMESPACE=\"dynamo-workshop\"\n",
    "\n",
    "# Watch pods being created and starting\n",
    "# Press Ctrl+C to stop watching\n",
    "kubectl get pods -n ${NAMESPACE} -w"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 8: Check Pod Logs (Optional)\n",
    "\n",
    "If you encounter issues, check the logs of the pods to see what's happening.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "export NAMESPACE=\"dynamo-workshop\"\n",
    "\n",
    "# Check logs of prefill workers\n",
    "kubectl logs -n ${NAMESPACE} -l component=prefill --tail=50\n",
    "\n",
    "# Check logs of decode workers\n",
    "kubectl logs -n ${NAMESPACE} -l component=decode --tail=50\n",
    "\n",
    "# Check frontend logs\n",
    "kubectl logs -n ${NAMESPACE} -l component=frontend --tail=50\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 9: Port Forward to Access the Frontend\n",
    "\n",
    "Create a port forward to access the deployment from your local machine. Keep this terminal running while testing.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "export NAMESPACE=\"dynamo-workshop\"\n",
    "\n",
    "# Port forward to access the frontend (run in background or separate terminal)\n",
    "kubectl port-forward svc/deepseek-r1-wideep-frontend 8000:8000 -n ${NAMESPACE}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 10: Test the Deployment with curl\n",
    "\n",
    "Send a test request to verify the deployment is working. Make sure the port-forward from the previous step is still running.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "# Test the deployment with a simple request\n",
    "curl http://localhost:8000/v1/chat/completions \\\n",
    "  -H \"Content-Type: application/json\" \\\n",
    "  -d '{\n",
    "    \"model\": \"deepseek-ai/DeepSeek-R1\",\n",
    "    \"messages\": [{\"role\": \"user\", \"content\": \"Explain MoE models in one sentence\"}],\n",
    "    \"max_tokens\": 100\n",
    "  }'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ‚úÖ Deployment Complete!\n",
    "\n",
    "If the curl command above returned a response, your Wide EP deployment is working! \n",
    "\n",
    "**Next Steps:**\n",
    "- Continue to Section 3 to learn about SGLang configuration details\n",
    "- Try the benchmarking exercises in Section 4\n",
    "- Explore the configuration files in `k8s/` directory\n",
    "\n",
    "**To clean up when done:**\n",
    "```bash\n",
    "# For single-node deployment\n",
    "kubectl delete -f k8s/deepseek-r1-8gpu-singlenode.yaml -n ${NAMESPACE}\n",
    "\n",
    "# For multi-node deployment\n",
    "# kubectl delete -f k8s/deepseek-r1-16gpu-multinode.yaml -n ${NAMESPACE}\n",
    "```\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "export NAMESPACE=\"dynamo-workshop\"\n",
    "kubectl delete -f k8s/deepseek-r1-8gpu-singlenode.yaml -n ${NAMESPACE}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 3: Deploying MoE Models with SGLang and Expert Parallelism\n",
    "\n",
    "Now that you understand how to deploy with Kubernetes, let's dive deeper into hands-on deployment of MoE models with Expert Parallelism using Dynamo's **SGLang backend**.\n",
    "\n",
    "**In this section, you'll learn:**\n",
    "- How to configure SGLang for Expert Parallelism\n",
    "- Single-node vs multi-node deployment strategies\n",
    "- EPLB configuration and tuning\n",
    "- Monitoring and troubleshooting EP deployments\n",
    "\n",
    "### Prerequisites for MoE Deployment\n",
    "\n",
    "**What you need**:\n",
    "- Multiple GPUs (minimum 4 GPUs for this example)\n",
    "- NATS and etcd running (infrastructure from Lab 2)\n",
    "- Model that fits with EP distribution\n",
    "- High-bandwidth interconnect (InfiniBand or NVLink preferred)\n",
    "\n",
    "**Check GPU availability**:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SGLang Deployment Configurations\n",
    "\n",
    "All SGLang configuration is done via command-line arguments in the Kubernetes manifests.\n",
    "\n",
    "**Available Manifests** (based on official Dynamo recipes):\n",
    "1. `k8s/deepseek-r1-8gpu-singlenode.yaml` - 8 GPUs (Example 1)\n",
    "2. `k8s/deepseek-r1-16gpu-multinode.yaml` - 16 GPUs (Example 2)\n",
    "\n",
    "Each manifest includes complete configuration for:\n",
    "- Expert Parallelism parameters (`--tp-size`, `--dp-size`, `--ep-size`)\n",
    "- EPLB settings (EP redundancy, load balancing)\n",
    "- Memory optimization (`--mem-fraction-static`)\n",
    "- Disaggregated prefill/decode workers with NIXL transfer\n",
    "\n",
    "**Reference**: [Official Dynamo Recipes](https://github.com/ai-dynamo/dynamo/tree/main/recipes/deepseek-r1/sglang-wideep)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List available Kubernetes manifests\n",
    "from pathlib import Path\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"Lab 3 DeepSeek-R1 Deployment Manifests\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "k8s_dir = Path(\"k8s\")\n",
    "if k8s_dir.exists():\n",
    "    manifests = [\n",
    "        (\"deepseek-r1-8gpu-singlenode.yaml\", \"Example 1: 8 GPUs (Single-Node)\"),\n",
    "        (\"deepseek-r1-16gpu-multinode.yaml\", \"Example 2: 16 GPUs (Multi-Node)\"),\n",
    "        (\"README.md\", \"Kubernetes Deployment Guide\")\n",
    "    ]\n",
    "    \n",
    "    print(\"\\nAvailable Manifests:\")\n",
    "    print(\"-\" * 60)\n",
    "    for filename, description in manifests:\n",
    "        file = k8s_dir / filename\n",
    "        if file.exists():\n",
    "            if filename.endswith('.yaml'):\n",
    "                size = file.stat().st_size\n",
    "                print(f\"  ‚úì {filename:<40} ({size:>6,} bytes)\")\n",
    "                print(f\"    {description}\")\n",
    "            else:\n",
    "                print(f\"  ‚úì {filename:<40} {description}\")\n",
    "else:\n",
    "    print(\"  ‚ö†Ô∏è  k8s/ directory not found\")\n",
    "\n",
    "print(\"\\nüìù Based on official Dynamo recipes:\")\n",
    "print(\"   https://github.com/ai-dynamo/dynamo/tree/main/recipes/deepseek-r1/sglang-wideep\")\n",
    "print(\"=\" * 60)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 1: Single-Node Workers (Recommended for 2 Nodes √ó 8 GPUs)\n",
    "\n",
    "**‚úÖ Use this configuration for your setup!** (2 nodes √ó 8 GPUs each = 16 GPUs total)\n",
    "\n",
    "This deploys DeepSeek-R1 with disaggregated prefill/decode workers, each worker running on a single node.\n",
    "\n",
    "**Manifest**: `k8s/deepseek-r1-8gpu-singlenode.yaml`\n",
    "\n",
    "**Architecture**:\n",
    "```\n",
    "                ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
    "                ‚îÇ  Frontend   ‚îÇ\n",
    "                ‚îÇ  (CPU only) ‚îÇ\n",
    "                ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
    "                       ‚îÇ\n",
    "           ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
    "           ‚îÇ                       ‚îÇ\n",
    "    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê       ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
    "    ‚îÇ Prefill Worker‚îÇ       ‚îÇ Decode Worker ‚îÇ\n",
    "    ‚îÇ   Node 1      ‚îÇ       ‚îÇ   Node 2      ‚îÇ\n",
    "    ‚îÇ   8 GPUs      ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ   8 GPUs      ‚îÇ\n",
    "    ‚îÇ               ‚îÇ NIXL  ‚îÇ               ‚îÇ\n",
    "    ‚îÇ  TP=8, EP=8   ‚îÇ  KV   ‚îÇ TP=8, DP=8    ‚îÇ\n",
    "    ‚îÇ               ‚îÇ       ‚îÇ EP=8, DP-Attn ‚îÇ\n",
    "    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò       ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
    "```\n",
    "\n",
    "**Configuration Details**:\n",
    "\n",
    "**Total Resources**: 16 GPUs across 2 nodes\n",
    "\n",
    "**Prefill Worker** (1 pod, 8 GPUs on Node 1):\n",
    "- TP=8: Model tensor parallelism across 8 GPUs (NVLink within node)\n",
    "- EP=8: 256 experts distributed across 8 GPUs\n",
    "- Processes prompt encoding\n",
    "- Transfers KV cache to decode via NIXL\n",
    "\n",
    "**Decode Worker** (1 pod, 8 GPUs on Node 2):\n",
    "- TP=8: Model tensor parallelism across 8 GPUs (NVLink within node)\n",
    "- DP=8: Data parallelism for batch processing\n",
    "- EP=8: Expert parallelism (256 experts distributed)\n",
    "- DP Attention: Parallel attention computation\n",
    "- Receives KV cache from prefill\n",
    "- Generates tokens autoregressively\n",
    "\n",
    "**Key Parameters**:\n",
    "```bash\n",
    "# Prefill Worker (Node 1)\n",
    "--model-path deepseek-ai/DeepSeek-R1\n",
    "--tp-size 8\n",
    "--ep-size 8\n",
    "--disaggregation-mode prefill\n",
    "--disaggregation-transfer-backend nixl\n",
    "\n",
    "# Decode Worker (Node 2)\n",
    "--model-path deepseek-ai/DeepSeek-R1\n",
    "--tp-size 8\n",
    "--dp-size 8\n",
    "--ep-size 8\n",
    "--enable-dp-attention\n",
    "--disaggregation-mode decode\n",
    "--disaggregation-transfer-backend nixl\n",
    "```\n",
    "\n",
    "**Why this configuration?**\n",
    "- ‚úÖ **Perfect for 2 nodes √ó 8 GPUs** (your hardware!)\n",
    "- ‚úÖ Each worker stays on one node - fast NVLink communication\n",
    "- ‚úÖ No cross-node TP overhead - better performance\n",
    "- ‚úÖ Simpler to deploy and debug\n",
    "- ‚úÖ Optimal for learning Wide EP concepts\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 2: Multi-Node Workers (For Larger Clusters)\n",
    "\n",
    "**Note**: This configuration is for clusters with **4+ nodes** and demonstrates advanced multi-node deployment patterns.\n",
    "\n",
    "**Your Setup**: You have **2 nodes √ó 8 GPUs = 16 GPUs**. Use **Example 1** (`deepseek-r1-8gpu-singlenode.yaml`).\n",
    "\n",
    "**Manifest**: `k8s/deepseek-r1-16gpu-multinode.yaml` (requires 4 nodes √ó 4 GPUs)\n",
    "\n",
    "**Architecture** (for 4-node clusters):\n",
    "```\n",
    "                ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
    "                ‚îÇ  Frontend   ‚îÇ\n",
    "                ‚îÇ  (CPU only) ‚îÇ\n",
    "                ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
    "                       ‚îÇ\n",
    "           ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
    "           ‚îÇ                         ‚îÇ\n",
    "    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
    "    ‚îÇ Prefill Worker    ‚îÇ     ‚îÇ Decode Worker    ‚îÇ\n",
    "    ‚îÇ  (Multi-node)     ‚îÇ     ‚îÇ  (Multi-node)    ‚îÇ\n",
    "    ‚îÇ                   ‚îÇ     ‚îÇ                  ‚îÇ\n",
    "    ‚îÇ ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îÇ     ‚îÇ ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îÇ\n",
    "    ‚îÇ ‚îÇNode 1      ‚îÇ    ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ ‚îÇNode 3      ‚îÇ   ‚îÇ\n",
    "    ‚îÇ ‚îÇ4 GPUs      ‚îÇ    ‚îÇNIXL ‚îÇ ‚îÇ4 GPUs      ‚îÇ   ‚îÇ\n",
    "    ‚îÇ ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îÇ KV  ‚îÇ ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ\n",
    "    ‚îÇ ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îÇ     ‚îÇ ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îÇ\n",
    "    ‚îÇ ‚îÇNode 2      ‚îÇ    ‚îÇ     ‚îÇ ‚îÇNode 4      ‚îÇ   ‚îÇ\n",
    "    ‚îÇ ‚îÇ4 GPUs      ‚îÇ    ‚îÇ     ‚îÇ ‚îÇ4 GPUs      ‚îÇ   ‚îÇ\n",
    "    ‚îÇ ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îÇ     ‚îÇ ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ\n",
    "    ‚îÇ                   ‚îÇ     ‚îÇ                  ‚îÇ\n",
    "    ‚îÇ Total: 8 GPUs     ‚îÇ     ‚îÇ Total: 8 GPUs    ‚îÇ\n",
    "    ‚îÇ TP=8, EP=8        ‚îÇ     ‚îÇ TP=8, DP=8, EP=8 ‚îÇ\n",
    "    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
    "```\n",
    "\n",
    "**Configuration Details**:\n",
    "\n",
    "**Total Resources**: 16 GPUs across **4 nodes** (4 GPUs per node)\n",
    "\n",
    "**Prefill Worker** (2 pods √ó 4 GPUs = 8 GPUs):\n",
    "- Multi-node: 2 pods across 2 nodes (Node 1 + Node 2)\n",
    "- TP=8: Model sharded across 8 GPUs (cross-node via NCCL)\n",
    "- EP=8: 256 experts distributed across 8 GPUs\n",
    "- Requires InfiniBand/RDMA for efficient cross-node communication\n",
    "\n",
    "**Decode Worker** (2 pods √ó 4 GPUs = 8 GPUs):\n",
    "- Multi-node: 2 pods across 2 nodes (Node 3 + Node 4)\n",
    "- TP=8: Model sharded across 8 GPUs (cross-node via NCCL)\n",
    "- DP=8: Data parallelism for batch processing\n",
    "- EP=8: Expert parallelism\n",
    "\n",
    "**When to use this**:\n",
    "- ‚ö†Ô∏è **You need 4 nodes** with 4 GPUs each (not 2 nodes with 8 GPUs each)\n",
    "- Shows advanced multi-node coordination\n",
    "- Demonstrates cross-node TP/EP communication\n",
    "- Requires excellent inter-node networking (25+ Gbps InfiniBand)\n",
    "\n",
    "**For your 2-node √ó 8 GPU setup**: Use Example 1 instead!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DeepSeek-R1 Deployment Examples\n",
    "# Choose the right configuration for your hardware\n",
    "\n",
    "print(\"\"\"\n",
    "=================================================================\n",
    "DeepSeek-R1 Wide EP Deployment Commands\n",
    "=================================================================\n",
    "\n",
    "Example 1: Single-Node Workers (‚úÖ USE THIS for 2 nodes √ó 8 GPUs)\n",
    "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "Manifest: k8s/deepseek-r1-8gpu-singlenode.yaml\n",
    "Deploy:   kubectl apply -f k8s/deepseek-r1-8gpu-singlenode.yaml\n",
    "\n",
    "Hardware: 2 nodes √ó 8 GPUs each = 16 GPUs total\n",
    "Architecture:\n",
    "  - Prefill: 1 pod √ó 8 GPUs on Node 1 (TP=8, EP=8)\n",
    "  - Decode:  1 pod √ó 8 GPUs on Node 2 (TP=8, DP=8, EP=8)\n",
    "  - Fast NVLink within each node, no cross-node TP overhead\n",
    "\n",
    "\n",
    "Example 2: Multi-Node Workers (‚ö†Ô∏è  Requires 4 nodes √ó 4 GPUs)\n",
    "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "Manifest: k8s/deepseek-r1-16gpu-multinode.yaml\n",
    "Deploy:   kubectl apply -f k8s/deepseek-r1-16gpu-multinode.yaml\n",
    "\n",
    "Hardware: 4 nodes √ó 4 GPUs each = 16 GPUs total (DIFFERENT from above!)\n",
    "Architecture:\n",
    "  - Prefill: 2 pods √ó 4 GPUs each (TP=8 cross-node)\n",
    "  - Decode:  2 pods √ó 4 GPUs each (TP=8 cross-node, DP=8, EP=8)\n",
    "  - Requires excellent inter-node networking (InfiniBand/RDMA)\n",
    "  - Only use if you have 4 nodes with 4 GPUs each\n",
    "\n",
    "\n",
    "üìù For your 2-node √ó 8 GPU setup, use Example 1!\n",
    "\n",
    "=================================================================\n",
    "\"\"\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Monitoring Expert Parallelism and EPLB\n",
    "\n",
    "When running MoE models with EP and EPLB, monitoring is crucial to ensure optimal performance.\n",
    "\n",
    "#### Key Metrics to Monitor\n",
    "\n",
    "**1. Expert Usage Distribution**\n",
    "```python\n",
    "# SGLang automatically logs expert usage statistics\n",
    "# Look for logs like:\n",
    "# \"Expert usage: [0.05, 0.12, 0.03, 0.15, ...]\"\n",
    "# These show the fraction of tokens routed to each expert\n",
    "```\n",
    "\n",
    "**2. GPU Utilization per Expert**\n",
    "```bash\n",
    "# Use nvidia-smi to check GPU utilization\n",
    "watch -n 1 nvidia-smi\n",
    "\n",
    "# For detailed metrics, use DCGM:\n",
    "dcgmi dmon -e 155,156,203,204 -d 1\n",
    "# 155 = GPU Utilization\n",
    "# 156 = Memory Utilization\n",
    "# 203 = Tensor Core Utilization\n",
    "# 204 = FP16 Activity\n",
    "```\n",
    "\n",
    "**3. EPLB Rebalancing Events**\n",
    "```python\n",
    "# Enable verbose logging to see EPLB rebalancing\n",
    "# Set environment variable: DYNAMO_LOG=debug\n",
    "\n",
    "# Look for logs like:\n",
    "# \"EPLB: Rebalancing experts after 100 iterations\"\n",
    "# \"EPLB: Expert 5 replicated to GPU 2 (high usage: 0.25)\"\n",
    "# \"EPLB: Expert 17 removed from GPU 3 (low usage: 0.01)\"\n",
    "```\n",
    "\n",
    "**4. Network Bandwidth (for Multi-Node)**\n",
    "```bash\n",
    "# Monitor InfiniBand bandwidth\n",
    "ibstat\n",
    "\n",
    "# Monitor network throughput\n",
    "iftop -i ib0  # Replace ib0 with your IB interface\n",
    "```\n",
    "\n",
    "#### Troubleshooting Common Issues\n",
    "\n",
    "**Issue 1: Uneven GPU Utilization**\n",
    "```\n",
    "Symptoms:\n",
    "- Some GPUs at 100%, others at <50%\n",
    "- Throughput lower than expected\n",
    "- Long token generation times\n",
    "\n",
    "Solution:\n",
    "- Enable EPLB: --enable-eplb\n",
    "- Increase redundant experts: --ep-num-redundant-experts 32\n",
    "- Adjust rebalancing frequency: --eplb-rebalance-num-iterations 50\n",
    "```\n",
    "\n",
    "**Issue 2: High Memory Usage**\n",
    "```\n",
    "Symptoms:\n",
    "- OOM errors\n",
    "- Cannot create redundant experts\n",
    "\n",
    "Solution:\n",
    "- Reduce memory fraction: --mem-fraction-static 0.80 (from 0.85)\n",
    "- Reduce redundant experts: --ep-num-redundant-experts 16\n",
    "- Disable features: --disable-radix-cache\n",
    "```\n",
    "\n",
    "**Issue 3: Slow Expert All-to-All Communication**\n",
    "```\n",
    "Symptoms:\n",
    "- High latency during expert routing\n",
    "- Low GPU utilization despite balanced load\n",
    "\n",
    "Solution:\n",
    "- Use DeepEP backend: --moe-a2a-backend deepep\n",
    "- Enable two-batch overlap: --enable-two-batch-overlap\n",
    "- Check network: Ensure InfiniBand is active and configured\n",
    "```\n",
    "\n",
    "**Issue 4: EPLB Not Rebalancing**\n",
    "```\n",
    "Symptoms:\n",
    "- No rebalancing logs\n",
    "- Expert usage remains imbalanced over time\n",
    "\n",
    "Solution:\n",
    "- Enable explicit EPLB: --enable-eplb\n",
    "- Use appropriate recorder mode: --expert-distribution-recorder-mode stat\n",
    "- Lower rebalance threshold: --eplb-rebalance-num-iterations 50\n",
    "```\n",
    "\n",
    "#### Performance Tuning Tips\n",
    "\n",
    "**1. Optimize Memory Allocation**\n",
    "```bash\n",
    "# Start with conservative memory fraction\n",
    "--mem-fraction-static 0.80\n",
    "\n",
    "# Gradually increase if no OOM\n",
    "--mem-fraction-static 0.85\n",
    "\n",
    "# Monitor with nvidia-smi\n",
    "```\n",
    "\n",
    "**2. Tune Redundant Expert Count**\n",
    "```bash\n",
    "# Formula: redundant_experts ‚âà num_GPUs / 2 to num_GPUs\n",
    "# For 32 GPUs: try 16-32 redundant experts\n",
    "\n",
    "# Start low\n",
    "--ep-num-redundant-experts 16\n",
    "\n",
    "# Increase if imbalance persists\n",
    "--ep-num-redundant-experts 32\n",
    "```\n",
    "\n",
    "**3. DeepEP Mode Selection**\n",
    "```bash\n",
    "# For prefill (focus on throughput)\n",
    "--deepep-mode normal\n",
    "\n",
    "# For decode (focus on latency)\n",
    "--deepep-mode low_latency\n",
    "```\n",
    "\n",
    "**4. Batch Size Tuning**\n",
    "```bash\n",
    "# For decode, tune CUDA graph batch size\n",
    "# Larger = better throughput, more memory\n",
    "--cuda-graph-bs 128\n",
    "\n",
    "# If OOM, reduce\n",
    "--cuda-graph-bs 64\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 4: Performance Benchmarking for EP Deployments\n",
    "\n",
    "Now that you've deployed Wide EP with SGLang, let's learn how to **measure and optimize performance**.\n",
    "\n",
    "**In this section, you'll learn:**\n",
    "- Key metrics for MoE model deployments\n",
    "- How to benchmark Expert Parallelism and EPLB\n",
    "- Comparing single-node vs multi-node performance\n",
    "- Measuring expert load balancing effectiveness\n",
    "\n",
    "### Objectives\n",
    "- Benchmark Expert Parallelism and EPLB performance\n",
    "- Compare single-node vs multi-node deployments\n",
    "- Measure expert load balancing effectiveness\n",
    "- Analyze throughput and latency characteristics\n",
    "\n",
    "### Key Metrics for MoE Models\n",
    "\n",
    "#### 1. **Throughput Metrics**\n",
    "```python\n",
    "# Requests per second across all replicas\n",
    "# Tokens per second (both input and output)\n",
    "# Expert activations per second\n",
    "```\n",
    "\n",
    "#### 2. **Latency Metrics**\n",
    "```python\n",
    "# Time to First Token (TTFT)\n",
    "# Time per Output Token (TPOT)  \n",
    "# Expert routing latency\n",
    "# All-to-all communication time\n",
    "```\n",
    "\n",
    "#### 3. **Load Balancing Metrics**\n",
    "```python\n",
    "# GPU utilization variance (should be low with EPLB)\n",
    "# Expert usage distribution (should be balanced)\n",
    "# EPLB rebalancing frequency\n",
    "# Redundant expert utilization\n",
    "```\n",
    "\n",
    "#### 4. **Resource Utilization**\n",
    "```python\n",
    "# GPU memory usage per worker\n",
    "# Network bandwidth (especially for multi-node)\n",
    "# CPU usage for pre/post-processing\n",
    "```\n",
    "\n",
    "### Benchmarking Exercise 1: Expert Load Distribution\n",
    "\n",
    "**Goal**: Measure how EPLB improves expert load balancing\n",
    "\n",
    "**Setup**:\n",
    "1. Deploy a MoE model WITHOUT EPLB\n",
    "2. Run workload and measure GPU utilization variance\n",
    "3. Enable EPLB and re-run same workload\n",
    "4. Compare results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import requests\n",
    "import statistics\n",
    "\n",
    "def benchmark_deployment(endpoint, num_requests=10):\n",
    "    \"\"\"Benchmark an EP deployment\"\"\"\n",
    "    print(f\"Benchmarking {endpoint}...\")\n",
    "    print(f\"Sending {num_requests} requests...\\n\")\n",
    "    \n",
    "    latencies = []\n",
    "    \n",
    "    for i in range(num_requests):\n",
    "        start = time.time()\n",
    "        try:\n",
    "            response = requests.post(\n",
    "                f\"{endpoint}/v1/chat/completions\",\n",
    "                json={\n",
    "                    \"model\": \"deepseek-ai/DeepSeek-R1\",\n",
    "                    \"messages\": [{\"role\": \"user\", \"content\": \"Hello\"}],\n",
    "                    \"max_tokens\": 50\n",
    "                },\n",
    "                timeout=30\n",
    "            )\n",
    "            latency = time.time() - start\n",
    "            latencies.append(latency)\n",
    "            print(f\"Request {i+1}: {latency:.2f}s\")\n",
    "        except Exception as e:\n",
    "            print(f\"Request {i+1}: Failed - {e}\")\n",
    "    \n",
    "    if latencies:\n",
    "        print(f\"\\nResults:\")\n",
    "        print(f\"  Mean latency: {statistics.mean(latencies):.2f}s\")\n",
    "        print(f\"  Median latency: {statistics.median(latencies):.2f}s\")\n",
    "        print(f\"  Throughput: {num_requests / sum(latencies):.2f} req/s\")\n",
    "\n",
    "# Example usage (uncomment when deployment is running):\n",
    "# benchmark_deployment(\"http://localhost:8000\", num_requests=10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "### What You Learned\n",
    "- ‚úÖ Wide EP deployments across multiple nodes with SGLang\n",
    "- ‚úÖ Expert Parallelism configuration and EPLB tuning\n",
    "- ‚úÖ Advanced performance measurement and optimization\n",
    "- ‚úÖ Production deployment best practices with Kubernetes\n",
    "- ‚úÖ Building custom Docker images with DeepEP support\n",
    "\n",
    "### Key Takeaways\n",
    "- Wide EP enables datacenter-scale MoE deployments\n",
    "- EPLB significantly improves load balancing and throughput\n",
    "- Multi-node deployments require careful network and resource planning\n",
    "- Custom Docker images are required for DeepEP backend support\n",
    "- SGLang provides flexible deployment and easier experimentation\n",
    "\n",
    "### Performance Improvements with Wide EP\n",
    "Key benefits you can expect:\n",
    "- **SGLang with DeepEP**: Optimized all-to-all communication for expert routing\n",
    "- **EPLB**: Balanced GPU utilization, preventing hotspots\n",
    "- **Multi-Node**: Horizontal scaling with proper network configuration\n",
    "- **Wide EP**: Better resource utilization across large GPU clusters\n",
    "- **Disaggregated Serving**: Separate prefill and decode workers for efficiency\n",
    "\n",
    "### Next Steps\n",
    "- Apply these techniques to your production deployments\n",
    "- Experiment with different configurations for your specific workloads\n",
    "- Contribute optimizations back to the Dynamo community\n",
    "- Explore the latest features in the [Dynamo repository](https://github.com/ai-dynamo/dynamo)\n",
    "\n",
    "---\n",
    "\n",
    "## Congratulations!\n",
    "\n",
    "You've completed the Dynamo Workshop. You now have the knowledge to:\n",
    "- Deploy Dynamo from local to datacenter scale\n",
    "- Choose the right topology for your use case\n",
    "- Optimize performance with Wide EP and EPLB\n",
    "- Operate production-grade LLM inference infrastructure\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
