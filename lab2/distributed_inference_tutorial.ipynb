{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Distributed Inference with Dynamo\n",
        "\n",
        "This interactive notebook guides you through deploying distributed inference with Dynamo on Kubernetes.\n",
        "\n",
        "## Prerequisites\n",
        "\n",
        "Before starting, ensure you have:\n",
        "- ✅ Kubernetes cluster with GPU support\n",
        "- ✅ `kubectl` and `helm` 3.x installed\n",
        "- ✅ HuggingFace token from [huggingface.co/settings/tokens](https://huggingface.co/settings/tokens)\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Part 1: Single-Node-Sized Models with Aggregated Serving\n",
        "\n",
        "Deploy multiple replicas of a model with KV cache-based routing for load balancing.\n",
        "\n",
        "### Configuration\n",
        "\n",
        "Set your configuration variables:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "# Set your configuration\n",
        "export RELEASE_VERSION=0.5.0\n",
        "export NAMESPACE=your-namespace-here  # Replace with your namespace\n",
        "export HF_TOKEN=your_huggingface_token  # Replace with your HuggingFace token\n",
        "export CACHE_PATH=/data/huggingface-cache  # Replace with your cache path\n",
        "\n",
        "echo \"✓ Configuration set:\"\n",
        "echo \"  Release Version: $RELEASE_VERSION\"\n",
        "echo \"  Namespace: $NAMESPACE\"\n",
        "echo \"  Cache Path: $CACHE_PATH\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Step 1: Install Dynamo CRDs\n",
        "\n",
        "**Note:** CRDs are cluster-wide resources and only need to be installed **once per cluster**. If already installed, skip to Step 2.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "# Check if CRDs already exist\n",
        "if kubectl get crd dynamographdeployments.nvidia.com &>/dev/null && \\\n",
        "   kubectl get crd dynamocomponentdeployments.nvidia.com &>/dev/null; then\n",
        "    echo \"✓ CRDs already installed, skipping to Step 2\"\n",
        "else\n",
        "    echo \"Installing Dynamo CRDs...\"\n",
        "    helm fetch https://helm.ngc.nvidia.com/nvidia/ai-dynamo/charts/dynamo-crds-${RELEASE_VERSION}.tgz\n",
        "    helm install dynamo-crds dynamo-crds-${RELEASE_VERSION}.tgz --namespace default\n",
        "    \n",
        "    echo \"\"\n",
        "    echo \"Verifying CRD installation:\"\n",
        "    kubectl get crd | grep nvidia.com\n",
        "fi\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Step 2: Install Dynamo Platform\n",
        "\n",
        "This installs ETCD, NATS, and the Dynamo Operator Controller in your namespace.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "# Create namespace\n",
        "kubectl create namespace ${NAMESPACE} 2>/dev/null || echo \"Namespace ${NAMESPACE} already exists\"\n",
        "\n",
        "# Download platform chart\n",
        "helm fetch https://helm.ngc.nvidia.com/nvidia/ai-dynamo/charts/dynamo-platform-${RELEASE_VERSION}.tgz\n",
        "\n",
        "# Install or upgrade\n",
        "if helm list -n ${NAMESPACE} | grep -q dynamo-platform; then\n",
        "    echo \"Upgrading Dynamo platform...\"\n",
        "    helm upgrade dynamo-platform dynamo-platform-${RELEASE_VERSION}.tgz --namespace ${NAMESPACE}\n",
        "else\n",
        "    echo \"Installing Dynamo platform...\"\n",
        "    helm install dynamo-platform dynamo-platform-${RELEASE_VERSION}.tgz --namespace ${NAMESPACE}\n",
        "fi\n",
        "\n",
        "echo \"\"\n",
        "echo \"Platform installation initiated. Checking status...\"\n",
        "kubectl get pods -n ${NAMESPACE}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Step 3: Configure and Deploy Model\n",
        "\n",
        "**⚠️ IMPORTANT:** Before deploying, we need to update the YAML configuration files with your specific values.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "# Update agg_router.yaml with your configuration\n",
        "cd examples/basics/kubernetes/Distributed_Inference\n",
        "\n",
        "# Replace my-tag with actual version\n",
        "sed -i '' \"s/my-tag/${RELEASE_VERSION}/g\" agg_router.yaml\n",
        "\n",
        "# Replace cache path\n",
        "sed -i '' \"s|/YOUR/LOCAL/CACHE/FOLDER|${CACHE_PATH}|g\" agg_router.yaml\n",
        "\n",
        "echo \"✓ Configuration updated in agg_router.yaml\"\n",
        "echo \"\"\n",
        "echo \"Verify image tags (should show version, not my-tag):\"\n",
        "grep \"image:\" agg_router.yaml\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Create HuggingFace secret and deploy:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "# Create HuggingFace token secret\n",
        "kubectl create secret generic hf-token-secret \\\n",
        "    --from-literal=HF_TOKEN=${HF_TOKEN} \\\n",
        "    --namespace ${NAMESPACE} 2>/dev/null || echo \"Secret already exists\"\n",
        "\n",
        "# Deploy the model\n",
        "kubectl apply -f agg_router.yaml --namespace ${NAMESPACE}\n",
        "\n",
        "echo \"\"\n",
        "echo \"✓ Deployment created. This will take 4-6 minutes for first run.\"\n",
        "echo \"  - Pulling container images\"\n",
        "echo \"  - Downloading model from HuggingFace\"\n",
        "echo \"  - Loading model and running torch.compile\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Monitor deployment progress:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "# Check deployment status\n",
        "kubectl get dynamographdeployment -n ${NAMESPACE}\n",
        "\n",
        "echo \"\"\n",
        "echo \"Pod status (wait for all pods to be 1/1 Ready):\"\n",
        "kubectl get pods -n ${NAMESPACE} | grep vllm\n",
        "\n",
        "# To watch in real-time, uncomment the line below:\n",
        "# kubectl get pods -n ${NAMESPACE} -w\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Step 4: Test the Deployment\n",
        "\n",
        "Once all pods are `1/1 Ready`, forward the service port (run this in a separate terminal or background):\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "# Forward the service port (run in background with &)\n",
        "kubectl port-forward deployment/vllm-agg-router-frontend 8000:8000 -n ${NAMESPACE} &\n",
        "\n",
        "echo \"✓ Port forward started on localhost:8000\"\n",
        "echo \"  (To stop: use 'pkill -f port-forward' or press Ctrl+C in the terminal running it)\"\n",
        "sleep 5  # Give it time to start\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Test 1: Simple Non-Streaming Request\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "curl localhost:8000/v1/chat/completions \\\n",
        "  -H \"Content-Type: application/json\" \\\n",
        "  -d '{\n",
        "    \"model\": \"Qwen/Qwen2.5-1.5B-Instruct\",\n",
        "    \"messages\": [{\"role\": \"user\", \"content\": \"Hello! How are you?\"}],\n",
        "    \"stream\": false,\n",
        "    \"max_tokens\": 50\n",
        "  }'\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Test 2: Streaming Request\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "curl localhost:8000/v1/chat/completions \\\n",
        "  -H \"Content-Type: application/json\" \\\n",
        "  -d '{\n",
        "    \"model\": \"Qwen/Qwen2.5-1.5B-Instruct\",\n",
        "    \"messages\": [{\"role\": \"user\", \"content\": \"Write a short poem about AI\"}],\n",
        "    \"stream\": true,\n",
        "    \"max_tokens\": 100\n",
        "  }'\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Part 2: Deploy with AIConfigurator\n",
        "\n",
        "AIConfigurator helps find optimal configurations for disaggregated serving by analyzing your model and hardware.\n",
        "\n",
        "### Step 1: Install AIConfigurator\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "pip3 install aiconfigurator\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Step 2: Run Configuration Analysis\n",
        "\n",
        "Example: Find optimal configuration for Llama 3.1-70B on 16 H200 GPUs\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "aiconfigurator cli default --model LLAMA3.1_70B --total_gpus 16 --system h200_sxm\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Step 3: Deploy with Recommended Settings\n",
        "\n",
        "Based on AIConfigurator output, update and deploy `disagg_router.yaml`:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "# Update disagg_router.yaml\n",
        "sed -i '' \"s/my-tag/${RELEASE_VERSION}/g\" disagg_router.yaml\n",
        "sed -i '' \"s|/YOUR/LOCAL/CACHE/FOLDER|${CACHE_PATH}|g\" disagg_router.yaml\n",
        "\n",
        "echo \"✓ Configuration updated\"\n",
        "grep \"image:\" disagg_router.yaml\n",
        "\n",
        "# Deploy\n",
        "kubectl apply -f disagg_router.yaml --namespace ${NAMESPACE}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Troubleshooting\n",
        "\n",
        "### Check if pods are stuck in ImagePullBackOff\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "# Check for image pull errors\n",
        "POD=$(kubectl get pods -n ${NAMESPACE} | grep vllm | grep -v Running | head -1 | awk '{print $1}')\n",
        "\n",
        "if [ -n \"$POD\" ]; then\n",
        "    echo \"Checking pod: $POD\"\n",
        "    kubectl describe pod $POD -n ${NAMESPACE} | grep -A 5 \"Failed\"\n",
        "else\n",
        "    echo \"✓ All pods are running successfully\"\n",
        "fi\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### View logs from a worker pod\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "# Get logs from first worker pod\n",
        "WORKER_POD=$(kubectl get pods -n ${NAMESPACE} | grep vllmdecodeworker | head -1 | awk '{print $1}')\n",
        "\n",
        "if [ -n \"$WORKER_POD\" ]; then\n",
        "    echo \"Viewing logs from: $WORKER_POD\"\n",
        "    echo \"Look for:\"\n",
        "    echo \"  - 'Loading model weights...' (downloading)\"\n",
        "    echo \"  - 'Model loading took X.XX GiB' (loaded)\"\n",
        "    echo \"  - 'torch.compile takes X.X s' (ready)\"\n",
        "    echo \"\"\n",
        "    kubectl logs $WORKER_POD -n ${NAMESPACE} --tail=50\n",
        "else\n",
        "    echo \"No worker pods found yet\"\n",
        "fi\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Cleanup\n",
        "\n",
        "To remove the deployment when done:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "# Delete deployment\n",
        "kubectl delete dynamographdeployment vllm-agg-router -n ${NAMESPACE}\n",
        "kubectl delete secret hf-token-secret -n ${NAMESPACE}\n",
        "\n",
        "# (Optional) Uninstall platform\n",
        "# helm uninstall dynamo-platform -n ${NAMESPACE}\n",
        "\n",
        "# (Optional) Delete namespace\n",
        "# kubectl delete namespace ${NAMESPACE}\n",
        "\n",
        "echo \"✓ Cleanup complete\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Additional Resources\n",
        "\n",
        "- 📖 [Dynamo Documentation](https://docs.dynamo.nvidia.com)\n",
        "- 🔧 [AIPerf Benchmarking Tool](https://github.com/ai-dynamo/aiperf)\n",
        "- 📦 [NGC Container Catalog](https://catalog.ngc.nvidia.com/orgs/nvidia/teams/ai-dynamo/containers/vllm-runtime)\n",
        "- 🎯 [vLLM Backend Guide](../../../components/backends/vllm/deploy/README.md)\n",
        "\n",
        "---\n",
        "\n",
        "**Congratulations! 🎉** You've successfully deployed Dynamo distributed inference on Kubernetes!\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
