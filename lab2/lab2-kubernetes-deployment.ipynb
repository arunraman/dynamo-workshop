{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Lab 2: Advanced Kubernetes Deployment\n",
        "\n",
        "## Overview\n",
        "\n",
        "In this lab, you will:\n",
        "- Deploy Dynamo on Kubernetes\n",
        "- Install and use the Dynamo Kubernetes operator\n",
        "- Deploy aggregated and disaggregated serving topologies\n",
        "- Deploy multiple models with a shared frontend\n",
        "- Use AI Configurator for optimal configurations\n",
        "\n",
        "## Duration: ~120 minutes\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Section 1: Kubernetes Setup and Verification\n",
        "\n",
        "### Objectives\n",
        "- Verify Kubernetes cluster access\n",
        "- Check GPU availability on nodes\n",
        "- Create namespace for Dynamo deployments\n",
        "- Review cluster resources\n",
        "\n",
        "### Tasks\n",
        "- [ ] Connect to Kubernetes cluster\n",
        "- [ ] Verify GPU nodes and resources\n",
        "- [ ] Create `dynamo` namespace\n",
        "- [ ] Install GPU operator (if not already installed)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Section 2: Install Dynamo Operator\n",
        "\n",
        "### Objectives\n",
        "- Understand the Dynamo Kubernetes operator\n",
        "- Install operator and CRDs\n",
        "- Verify operator installation\n",
        "\n",
        "### Dynamo Operator Features\n",
        "- Automated deployment of Dynamo components\n",
        "- Custom Resource Definitions (CRDs) for declarative management\n",
        "- Automatic service discovery and coordination\n",
        "- Health monitoring and self-healing\n",
        "\n",
        "### Tasks\n",
        "- [ ] Install Dynamo operator\n",
        "- [ ] Verify CRDs are registered\n",
        "- [ ] Check operator pod status\n",
        "- [ ] Review operator logs\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Section 3: Deploy Aggregated Serving\n",
        "\n",
        "### Objectives\n",
        "- Deploy Dynamo in aggregated mode\n",
        "- Understand aggregated serving architecture\n",
        "- Configure and deploy etcd, NATS, frontend, and workers\n",
        "\n",
        "### Aggregated Architecture\n",
        "```\n",
        "Frontend → Router → Worker Pods (Prefill + Decode together)\n",
        "```\n",
        "\n",
        "### Tasks\n",
        "- [ ] Review aggregated deployment manifest\n",
        "- [ ] Deploy etcd and NATS\n",
        "- [ ] Deploy Dynamo frontend\n",
        "- [ ] Deploy aggregated workers\n",
        "- [ ] Verify deployment\n",
        "- [ ] Send test requests\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Section 4: Deploy Multiple Models with Shared Frontend\n",
        "\n",
        "### Objectives\n",
        "- Deploy multiple model workers\n",
        "- Configure shared frontend and router\n",
        "- Implement model routing\n",
        "- Test multi-model serving\n",
        "\n",
        "### Architecture\n",
        "```\n",
        "                    Frontend (Shared)\n",
        "                         |\n",
        "                      Router\n",
        "                    /         \\\n",
        "            Model-A Workers   Model-B Workers\n",
        "```\n",
        "\n",
        "### Tasks\n",
        "- [ ] Deploy first model (e.g., Llama-2-7B)\n",
        "- [ ] Deploy second model (e.g., DeepSeek-R1-Distill-8B)\n",
        "- [ ] Configure router for multi-model support\n",
        "- [ ] Test routing to different models\n",
        "- [ ] Verify load balancing across workers\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Section 5: Deploy Disaggregated Serving\n",
        "\n",
        "### Objectives\n",
        "- Understand disaggregated serving architecture\n",
        "- Deploy disaggregator component\n",
        "- Configure prefill and decode workers separately\n",
        "- Compare performance with aggregated serving\n",
        "\n",
        "### Disaggregated Architecture\n",
        "```\n",
        "Frontend → Router → Disaggregator → Prefill Workers\n",
        "                          ↓\n",
        "                    Decode Workers\n",
        "                          ↓\n",
        "                    KV Cache Store\n",
        "```\n",
        "\n",
        "### Benefits of Disaggregation\n",
        "- Independent scaling of prefill and decode\n",
        "- Better resource utilization\n",
        "- Improved throughput for mixed workloads\n",
        "- KV cache reuse across requests\n",
        "\n",
        "### Tasks\n",
        "- [ ] Review disaggregated deployment manifest\n",
        "- [ ] Deploy disaggregator component\n",
        "- [ ] Deploy prefill workers\n",
        "- [ ] Deploy decode workers\n",
        "- [ ] Configure KV cache storage\n",
        "- [ ] Verify disaggregated deployment\n",
        "- [ ] Run performance comparison\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Section 6: AI Configurator\n",
        "\n",
        "### Objectives\n",
        "- Use AI Configurator to generate optimal configurations\n",
        "- Understand how AI Configurator analyzes workloads\n",
        "- Apply recommended configurations\n",
        "\n",
        "### AI Configurator Features\n",
        "- Automatic configuration generation based on:\n",
        "  - Model size and architecture\n",
        "  - Available GPU resources\n",
        "  - Expected workload patterns\n",
        "  - SLA requirements\n",
        "\n",
        "### Tasks\n",
        "- [ ] Install AI Configurator\n",
        "- [ ] Provide workload requirements\n",
        "- [ ] Generate configuration recommendations\n",
        "- [ ] Review and understand recommendations\n",
        "- [ ] Apply optimized configuration\n",
        "- [ ] Measure performance improvements\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Section 7: Reference Example\n",
        "\n",
        "### Distributed Inference Example\n",
        "\n",
        "Reference the official Dynamo example:\n",
        "- [Kubernetes Distributed Inference Example](https://github.com/ai-dynamo/dynamo/tree/main/examples/basics/kubernetes/Distributed_Inference)\n",
        "\n",
        "### Key Files to Review\n",
        "- Deployment manifests\n",
        "- Service configurations\n",
        "- ConfigMaps and Secrets\n",
        "- Resource requests and limits\n",
        "\n",
        "### Tasks\n",
        "- [ ] Clone the example repository\n",
        "- [ ] Review manifest structure\n",
        "- [ ] Adapt example for your use case\n",
        "- [ ] Deploy and test\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Section 8: Monitoring and Troubleshooting\n",
        "\n",
        "### Objectives\n",
        "- Monitor Dynamo deployments\n",
        "- Troubleshoot common issues\n",
        "- View logs and metrics\n",
        "\n",
        "### Tasks\n",
        "- [ ] Check pod status and logs\n",
        "- [ ] Monitor GPU utilization\n",
        "- [ ] Review service discovery in etcd\n",
        "- [ ] Check NATS message flow\n",
        "- [ ] Troubleshoot connection issues\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Section 9: Exercises\n",
        "\n",
        "### Exercise 1: Scale Workers\n",
        "- Scale worker replicas up and down\n",
        "- Observe automatic load balancing\n",
        "\n",
        "### Exercise 2: Compare Topologies\n",
        "- Benchmark aggregated vs disaggregated\n",
        "- Analyze performance trade-offs\n",
        "\n",
        "### Exercise 3: Multi-Model Routing\n",
        "- Send requests to different models\n",
        "- Measure routing overhead\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Summary\n",
        "\n",
        "### What You Learned\n",
        "- ✅ Kubernetes deployment of Dynamo\n",
        "- ✅ Dynamo operator usage\n",
        "- ✅ Aggregated and disaggregated serving topologies\n",
        "- ✅ Multi-model deployments with shared frontend\n",
        "- ✅ AI Configurator for optimal configurations\n",
        "\n",
        "### Key Takeaways\n",
        "- Disaggregated serving offers better scalability for production workloads\n",
        "- Multi-model serving with shared infrastructure reduces costs\n",
        "- AI Configurator simplifies deployment optimization\n",
        "- Kubernetes operator automates complex deployment patterns\n",
        "\n",
        "### Next Steps\n",
        "In **Lab 3**, you'll explore wide EP deployments across multiple nodes and KVBM for advanced KV cache management.\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
